Device configured: cuda:0
Starting training loop...
Traceback (most recent call last):
  File "run.py", line 260, in <module>
    train(ncf, datasets)
  File "D:\University\Edinburgh\Dissertation\MM_RecSys_Amazon\training.py", line 118, in train
    outputs = ncf(x_batch[:, 0], x_batch[:, 1])
  File "C:\Users\nikol\anaconda3\envs\ptvqa\lib\site-packages\torch\nn\modules\module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "D:\University\Edinburgh\Dissertation\MM_RecSys_Amazon\model_user_data.py", line 233, in forward
    user_features = self.user_embedding(user_id % self.user_hash_size)
  File "C:\Users\nikol\anaconda3\envs\ptvqa\lib\site-packages\torch\nn\modules\module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\nikol\anaconda3\envs\ptvqa\lib\site-packages\torch\nn\modules\sparse.py", line 160, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "C:\Users\nikol\anaconda3\envs\ptvqa\lib\site-packages\torch\nn\functional.py", line 2044, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: isDifferentiableType(variable.scalar_type())INTERNAL ASSERT FAILED at "..\\torch/csrc/autograd/functions/utils.h":65, please report a bug to PyTorch.