{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "data = pd.read_pickle(\"data_after_process.pkl\")\n",
    "data[\"movie_descr\"] = data[\"title\"] + \" \" + data[\"overview\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_descr = data[\"movie_descr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Toy Story Led by Woody, Andy's toys live happi...\n",
       "1       Jumanji When siblings Judy and Peter discover ...\n",
       "2       Grumpier Old Men A family wedding reignites th...\n",
       "3       Waiting to Exhale Cheated on, mistreated and s...\n",
       "4       Father of the Bride Part II Just when George B...\n",
       "                              ...                        \n",
       "9020    Betty Boop's Museum Koko is recruiting custome...\n",
       "9021    Angora Love Stanley and Oliver are adopted by ...\n",
       "9022    Woman of Tokyo Ryoichi and Chikako, brother an...\n",
       "9023    Scaramouche A law student becomes an outlaw Fr...\n",
       "9024    Band of Brothers Drawn from interviews with su...\n",
       "Name: movie_descr, Length: 9025, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_descr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_descr[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "maxLength = 177 \n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "encoder = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "encoded_x = []\n",
    "for index in range(20):\n",
    "   # print(data[\"overview\"].iloc[index])\n",
    "   # movie_descr = str(data[\"title\"].iloc[index]) + \" \" + str(data[\"overview\"].iloc[index])\n",
    "   # print(movie_descr)\n",
    "   tokenizer_output = tokenizer(movie_descr[index], max_length=maxLength, padding=\"max_length\", truncation=True, return_tensors=\"pt\") \n",
    "   # tokens, masks = tokenizer_output['input_ids'], tokenizer_output['attention_mask']\n",
    "   encoded_x.append(encoder(input_ids=tokenizer_output['input_ids'], attention_mask=tokenizer_output['attention_mask'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4134, -0.1026, -0.0859,  ...,  0.1004,  0.4729,  0.3154],\n",
       "         [ 0.0496,  0.3076, -0.1006,  ...,  0.1970,  0.9127,  0.1872],\n",
       "         [ 0.2023, -0.1425,  0.1762,  ...,  0.2362,  0.1194, -0.0266],\n",
       "         ...,\n",
       "         [-0.1070, -0.0188,  0.3462,  ...,  0.1914,  0.0435, -0.1268],\n",
       "         [-0.1704,  0.0302,  0.2782,  ...,  0.2994, -0.0686, -0.1351],\n",
       "         [-0.0519, -0.0652, -0.1020,  ..., -0.1981, -0.1734, -0.1947]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('PTVQA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3211dc43ab34930f11a9a22ea04b20f87c15e7fbdb07e5e2aecfd06158e2e37a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
